{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "* increase chunk size - 5k+\n",
    "* increase games count\n",
    "* adaptive learning rate\n",
    "* batch normalization\n",
    "* focus on mid-end game\n",
    "* more comment tips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import DataLoader # type: ignore\n",
    "from chess import pgn # type: ignore\n",
    "import tqdm # type: ignore\n",
    "from dataset import ChessDataset\n",
    "from model import ChessModel\n",
    "from helper_funcs import collect_unique_moves, create_input_for_nn\n",
    "from helper_funcs import process_data_and_save_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data - into chunks so that memory is not overwhelmed, store them in sepearte folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Moves:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Moves:   0%|          | 0/1 [01:58<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "files = [os.path.join(\"../data/pgn\", file) for file in os.listdir(\"../data/pgn\") if file.endswith(\".pgn\")]\n",
    "files.sort()  # Ensure consistent order\n",
    "LIMIT_OF_FILES = min(len(files), 28)\n",
    "files = files[:LIMIT_OF_FILES]\n",
    "\n",
    "# Collect unique moves\n",
    "move_to_int, num_classes = collect_unique_moves(files, max_games=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data Chunks:   0%|          | 0/1 [34:15<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data_chunk_files = process_data_and_save_chunks(files, move_to_int, chunk_size=5000, max_games=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend on Apple Silicon (M2).\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS backend on Apple Silicon (M2).\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MPS backend not available. Using CPU.\")\n",
    "\n",
    "# Model Initialization\n",
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "    for data_chunk_file in tqdm.tqdm(data_chunk_files, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # Load data chunk\n",
    "        data = np.load(data_chunk_file)\n",
    "        X = torch.tensor(data['X'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['y'], dtype=torch.long)\n",
    "        # Create Dataset and DataLoader\n",
    "        dataset = ChessDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, num_workers=4, shuffle=True)\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Raw logits\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        # Free up memory\n",
    "        del X, y, dataset, dataloader\n",
    "        # Clear cache on mac m2\n",
    "        # if device == torch.device('mps'):\n",
    "        #     torch.mps.current_process.cache_clear()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes = int(epoch_time // 60)\n",
    "    seconds = int(epoch_time % 60)\n",
    "    avg_loss = running_loss / total_batches\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {minutes}m{seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"../models/mark1-10e.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
