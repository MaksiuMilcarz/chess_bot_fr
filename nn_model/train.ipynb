{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "More quiality data:\n",
    "* take games with different openings to ensure variaty - maybe allow more openings - change the coefficient?\n",
    "* train mostly on roughly fair, equal possitions\n",
    "\n",
    "* Reinforcement Learning\n",
    "\n",
    "* Create an app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.optim.lr_scheduler import OneCycleLR # type: ignore\n",
    "import math\n",
    "from torch.utils.data import DataLoader # type: ignore\n",
    "from chess import pgn # type: ignore\n",
    "import tqdm # type: ignore\n",
    "from dataset import ChessDataset\n",
    "from model import ChessModel\n",
    "from helper_funcs import collect_unique_moves, create_input_for_nn\n",
    "from helper_funcs import process_data_and_save_chunks\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data - into chunks so that memory is not overwhelmed, store them in sepearte folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Moves:  50%|█████     | 1/2 [14:46<14:46, 886.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = [os.path.join(\"../data/pgn\", file) for file in os.listdir(\"../data/pgn\") if file.endswith(\".pgn\")]\n",
    "files.sort()  # Ensure consistent order\n",
    "LIMIT_OF_FILES = min(len(files), 28)\n",
    "files = files[:LIMIT_OF_FILES]\n",
    "\n",
    "max_games = 500000\n",
    "chunk_size = 25000\n",
    "\n",
    "# Collect unique moves\n",
    "move_to_int, num_classes = collect_unique_moves(files, max_games=max_games)\n",
    "\n",
    "with open(\"../models/mark4_move_to_int.pkl\", \"wb\") as file:\n",
    "    pickle.dump(move_to_int, file)\n",
    "    \n",
    "print(\"Number of classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data Chunks:  50%|█████     | 1/2 [30:32<30:32, 1832.85s/it]\n"
     ]
    }
   ],
   "source": [
    "data_chunk_files = process_data_and_save_chunks(files, move_to_int, chunk_size=chunk_size, max_games=max_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS backend on Apple Silicon (M2).\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MPS backend not available. Using CPU.\")\n",
    "    \n",
    "# Model Initialization\n",
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "batch_size = 64  # Ensure this matches your DataLoader batch_size\n",
    "total_batches_per_epoch = 0\n",
    "for data_chunk_file in data_chunk_files:\n",
    "    data = np.load(data_chunk_file)\n",
    "    num_samples = data['X'].shape[0]\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    total_batches_per_epoch += num_batches\n",
    "\n",
    "total_steps = num_epochs * total_batches_per_epoch\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.001, total_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "    for data_chunk_file in tqdm.tqdm(data_chunk_files, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # Load data chunk\n",
    "        data = np.load(data_chunk_file)\n",
    "        X = torch.tensor(data['X'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['y'], dtype=torch.long)\n",
    "        # Create Dataset and DataLoader\n",
    "        dataset = ChessDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, num_workers=4, shuffle=True)\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Raw logits\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        # Free up memory\n",
    "        del X, y, dataset, dataloader\n",
    "        gc.collect()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes = int(epoch_time // 60)\n",
    "    seconds = int(epoch_time % 60)\n",
    "    avg_loss = running_loss / total_batches\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {minutes}m{seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"../models/mark3-15e-300k.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark 1 - 10e - 50k\n",
    "* base; 5k chunks, 14 boards reprezentation\n",
    "* 10 minutes per epoch - 50k games\n",
    "\n",
    "# Mark 2 - 20e - 100k\n",
    "* 10k chunks\n",
    "* adaptive learning rate\n",
    "* probabilistic favourizm of mid-late game states\n",
    "* batch normalization after convolutional layer\n",
    "\n",
    "# Mark 3 - 35e - 300k(sampled)\n",
    "* 300k - 10k chunks - 35e\n",
    "* its useable :D - forgot to load the mapping and data is sampled randomly\n",
    "* added additional garbage collection at the ends of the epochs\n",
    "* better to go for more games "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue Training If crushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import your custom modules\n",
    "from dataset import ChessDataset\n",
    "from model import ChessModel\n",
    "from helper_funcs import collect_unique_moves, process_data_and_save_chunks\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS backend on Apple Silicon (M2).\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MPS backend not available. Using CPU.\")\n",
    "\n",
    "# Load the move_to_int mapping\n",
    "with open(\"../models/mark3_move_to_int.pkl\", \"rb\") as file:\n",
    "    move_to_int = pickle.load(file)\n",
    "num_classes = len(move_to_int)\n",
    "\n",
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/mark3.4-35e.pth\", map_location=device))\n",
    "\n",
    "max_games = 300000\n",
    "chunk_size = 10000\n",
    "\n",
    "# Assuming data_chunk_files are available\n",
    "data_chunk_files = [f for f in os.listdir('.') if f.startswith('data_chunk_') and f.endswith('.npz')]\n",
    "data_chunk_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_chunk_files = [f for f in os.listdir('.') if f.startswith('data_chunk_') and f.endswith('.npz')]\n",
    "for file in data_chunk_files:\n",
    "    try:\n",
    "        with np.load(file) as data:\n",
    "            print(f\"{file} loaded successfully\")\n",
    "    except EOFError:\n",
    "        print(f\"{file} is corrupted or incomplete.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_epochs = 15  \n",
    "batch_size = 64  \n",
    "total_batches_per_epoch = 0\n",
    "for data_chunk_file in data_chunk_files:\n",
    "    data = np.load(data_chunk_file)\n",
    "    num_samples = data['X'].shape[0]\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    total_batches_per_epoch += num_batches\n",
    "    data.close()\n",
    "\n",
    "total_steps = additional_epochs * total_batches_per_epoch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.001, total_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(additional_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "    for data_chunk_file in tqdm(data_chunk_files, desc=f'Epoch {epoch+1}/{additional_epochs}'):\n",
    "        # Load data chunk\n",
    "        data = np.load(data_chunk_file)\n",
    "        X = torch.tensor(data['X'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['y'], dtype=torch.long)\n",
    "        data.close()\n",
    "        # Create Dataset and DataLoader\n",
    "        dataset = ChessDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Raw logits\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        # Free up memory\n",
    "        del X, y, dataset, dataloader\n",
    "        gc.collect()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes = int(epoch_time // 60)\n",
    "    seconds = int(epoch_time % 60)\n",
    "    avg_loss = running_loss / total_batches\n",
    "    print(f'Epoch {epoch + 1}/{additional_epochs}, Loss: {avg_loss:.4f}, Time: {minutes}m{seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated model\n",
    "torch.save(model.state_dict(), \"../models/mark3.5-50e.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
