{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chess tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.optim.lr_scheduler import OneCycleLR # type: ignore\n",
    "import math\n",
    "from torch.utils.data import DataLoader # type: ignore\n",
    "from chess import pgn # type: ignore\n",
    "import tqdm # type: ignore\n",
    "from dataset import ChessDataset\n",
    "from model import ChessModel\n",
    "from helper_funcs import collect_unique_moves, create_input_for_nn\n",
    "from helper_funcs import process_data_and_save_chunks\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "save_dir = '/content/drive/MyDrive/models'\n",
    "os.makedirs(save_dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using cuda backend \")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MPS backend not available. Using CPU.\")\n",
    "\n",
    "num_classes = 1941\n",
    "    \n",
    "# Model Initialization\n",
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "data_chunk_files = [f'data_chunk_{i}.npz' for i in range(21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "batch_size = 320  # Ensure this matches your DataLoader batch_size\n",
    "total_batches_per_epoch = 0\n",
    "for data_chunk_file in data_chunk_files:\n",
    "    data = np.load(data_chunk_file)\n",
    "    num_samples = data['X'].shape[0]\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    total_batches_per_epoch += num_batches\n",
    "\n",
    "total_steps = num_epochs * total_batches_per_epoch\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.001, total_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "    for data_chunk_file in tqdm.tqdm(data_chunk_files, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # Load data chunk\n",
    "        data = np.load(data_chunk_file)\n",
    "        X = torch.tensor(data['X'], dtype=torch.float32).to(device)\n",
    "        y = torch.tensor(data['y'], dtype=torch.long).to(device)\n",
    "        # Create Dataset and DataLoader\n",
    "        dataset = ChessDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=320, num_workers=0, shuffle=True)\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Raw logits\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        # Free up memory\n",
    "        del X, y, dataset, dataloader\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes = int(epoch_time // 60)\n",
    "    seconds = int(epoch_time % 60)\n",
    "    avg_loss = running_loss / total_batches\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {minutes}m{seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(save_dir, 'mark4.3-25e-500k.pth')\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f'Model saved to {save_path}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
